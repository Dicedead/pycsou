pyxu.info.deps
    CuPy support is temporarily locked to v12.x max.

    Reason: v13.0 no longer triggers ImportError if CUDA is not available on the system.
    This has implications on how pyxu.info.deps.CUDA_ENABLED and the NDArrayInfo.CUPY.
    Until this is sorted out, we support until CuPy 12.x only.

doc/
    api/ has/is-being updated to ND API interactively.

pyxu.abc.solver
    Allow not writing data to disk at end.
        writeback_rate = None -> don't write (ever)
                         -1   -> only at convergence
                          N   -> every N-th iteration
    Replace .npz file storage with ZARR format.
        Add test_disk_chunk_matches_memory() [but this will never be tested since we disabled DASK solvers?]
            We should instantiate only one solver to verify this.

pyxu.opt.nlcg
    Refactor to ND API. (2023.12.29: not started yet.)
        Update test_nlcg.py
    Need to ensure math.backtracking_linesearch() works beforehand.
        Fix first. (See associated issue below.)

pyxu.math.backtracking_linesearch()
    Add test suite under math/linesearch/test_backtrack.py
        Testing this function requires similar code to conftest.FuncT().
            Wrap it into a Func() and piggy-back on FuncT().
                Extra args go into __init__()
            Disable all irrelevant tests as required.
    Known to be broken for DASK inputs ... and maybe for NUMPY/CUPY too.
        Fix it guided by test suite.
    Known to be algorithmically inefficient for DASK inputs.
        Call pxw.warn_dask_perf()

pyxu.math.cluster
    [grid,bisect]_cluster() don't depend on KDTree() anymore, hence can be refactored to work with CUPY arrays too.

pyxu.opt.adam
    Refactor to ND API. (2023.12.29: not started yet.)
        Update test_adam.py

pyxu.opt.pds
    Remove CP, FB, PP? They are only passing args to CV or PD3O (other solvers rely on CV or PD3O but have different step sizes).

pyxu.operator.interop.jax
    Code + test suite has been ported to ND API.
    [2023.12.29] CPU tests mostly pass, except a few items in
        TestJax[PSD,SelfAdjoint]Convolution
            Hypothesis: when porting to Jax, convolution implemented incorrectly.
            We copied what was done in CircularConvolution, but an error may have been introduced in the process.
        TestJaxScaleDown
            svdvals()-errors?
    Implementations of asarray() and _quad_spec() were simplified, but not sure if it broke anything.
        Correctness of asarray() is simple to verify via the test suite.
        Correctness of _quad_spec() is not assessed since a suitable test structure differs significantly from the other Operator classes.
            Assess correctness on small instantiations.

    Implement to_jax(Operator) to make Pyxu operators available to the JAX ecosystem.
        Idea: to_jax() returns a NamedTuple of following fields (subset of arithmetic methods):
            def apply(arr: jax.Array) -> jax.Array                  # (..., M1,...,MD) -> (..., N1,...,NK)
            def grad(arr: jax.Array) -> jax.Array                   # (..., M1,...,MD) -> (..., M1,...,MD)
            def adjoint(arr: jax.Array) -> jax.Array                # (..., N1,...,NK) -> (..., M1,...,MD)
            def prox(arr: jax.Array, tau: pxt.Real) -> jax.Array    # (..., M1,...,MD) -> (..., M1,...,MD)
            def pinv(arr: jax.Array, damp: pxt.Real) -> jax.Array   # (..., N1,...,NK) -> (..., M1,...,MD)
        Need to create these methods by encapsulating Pyxu functions.

pyxu.operator.interop.torch
    [2024.03.02] Updated to ND API
    The PyTorch interface is slightly different from the JAX interface; it would be ideal to homogenize them.
    Add a test suite similar to test_jax.py

pyxu.operator.blocks
    Long-term plan for blocks:
        Pyxu is 2 things:
            * A collection of efficient *scalable* operators to work on NDArrays.
            * A collection of solvers and other niceities to solve optimization problems.

        We already achieve both these goals with the current API.

        One downside however is that the operator arithmetic is strongly tied to the (array-in -> array-out) assumption.
        This means:
            * we cannot have operators which take multiple inputs and return multiple outputs; instead one needs
              currently to flatten/stack input/outputs to feed them to operators.
            * solvers return ONE output: it is not possible to optimize different parameters simultaneously without
              flat/stack-ing them all. (Consequence of former point.)

        One solution would be to replace arithmetic methods in the Operator API to instead accept list[NDArray] inputs and output list[NDArray].
        Solvers would then accept list[NDArray] initial points & save list[NDArray] to disk.
        The issue with this solution is that most (if not all) core operators have no meaning on list[NDArray] inputs. (Ex: FFT of a list; what does that mean exactly? etc.)
        Therefore list[NDArray] in/outputs are a consequence of operator arithmetic only, and solvers need to be able to handle these in/output pairs.

        [Proposition] introduce a CompositeOperator class with the following interface:

            class CompositeOp(Operator):
                def __init__(ops)
                    ops: CompositeOp -> no-op
                    ops: list[Operator] -> see op()

                def op() -> Namespace()
                    Identify all operators involved in creating `ops`.
                        Form the full operator chain, then prune nodes which are not required to compute the desired outputs.
                    Infer global operator type (LinOp, etc.) based on the global graph.
                    Redefine arithmetic methods to eval all terms in parallel via
                        [NUMPY/CUPY] concurrent.futures
                        [DASK] Its own task graph
                    Arithmetic methods now all take/return a special Array() class.
                        Array = thin layer around dict[str, NDArray] with simple rules for +/-/*[for scaling]

            This interface requires ZERO changes to the current arithmetic API.
            The only difference is that solvers can take either Operator or CompositeOp as input and handle outputs accordingly.
            Concretely all Operators should be cast to CompositeOperator instances; and solver m_init/m_step handle composite operators only.
            Solver must be updated to write multiple arrays to disk.

            Composite op completely replaces blocks.py and will be part of abc/.

pyxu.operator.linop.kron
    Refactor to ND API. (2024.01.01: not started yet.)
        Update test_kron.py

pyxu.operator.linop.fft.czt
    There are known closed forms for gram()/cogram(), hence pinv(): implement them.

pyxu.operator.linop.fft.nufft
    Move old FINUFFT-based NUFFT implementations to an extension module.

    Pyxu-core built-in NUFFTs currently limited to NUMPY/DASK due to UniformSpread's NUMPY/DASK limitation.
    Since _build_cl_info() no longer depends on kd-trees, adding CUPY support to type-1/2 is simple once UniformSpread becomes CUPY-compliant.
    [It is advised to change (window_ratio, max_cluster_size) for GPU workloads though.]

    Type-3: CuPy backend currently disabled.
        At the implementation level, the code is GPU-compatible.  The issue is just _partition_domain() and _init_metadata() which need updates to output CuPy arrays in some places.


Known Issues: Cause Unknown (Investigate)
    TestTan::test_transparent_call
    TestTanh::test_math_diff_lipschitz
    TestArcCosh::test_math_lipschitz
    TestArcCosh::test_math_diff_lipschitz
    TestSign::test_math_lipschitz
    TestHyperSlab::test_math_prox
    TestL1Ball::test_backend_fenchel_prox
    TestL1Ball::test_backend_prox
    TestL1Ball::test_chunk_fenchel_prox
    TestL1Ball::test_chunk_prox
    TestL1Ball::test_math_prox
    TestL1Ball::test_math1_moreau_envelope
    TestL1Ball::test_math2_moreau_envelope
    TestL1Ball::test_prec_fenchel_prox
    TestL1Ball::test_prec_prox
    TestL1Ball::test_precCM_fenchel_prox
    TestL1Ball::test_precCM_prox
    TestL1Ball::test_transparent_fenchel_prox
    TestL1Ball::test_transparent_prox
    TestL1Ball::test_value1D_fenchel_prox
    TestL1Ball::test_value1D_prox
    TestL1Ball::test_valueND_fenchel_prox
    TestL1Ball::test_valueND_prox
    TestRangeSet::test_chunk_prox
    TestRangeSet::test_transparent_apply
    TestRangeSet::test_transparent_call
    TestRangeSet::test_value1D_apply
    TestRangeSet::test_value1D_call
    TestRangeSet::test_valueND_apply
    TestRangeSet::test_valueND_call
    TestCZT::test_chunk_pinv [hangs for DASK inputs]
Known Issues: Cause Known (& Fixable?)
    [OK] Due to DASK-suboptimal tensordot()
        TestExplicitLinXX::test_chunk_adjoint
        TestExplicitLinXX::test_chunk_apply
        TestExplicitLinXX::test_chunk_call
        TestExplicitLinXX::test_chunk_fenchel_prox
        TestExplicitLinXX::test_chunk_grad
        TestExplicitLinXX::test_chunk_pinv
    [OK] DASK-case: Fixture[_op_array] cannot instantiate due to chunk-size mismatch.
         Can be fixed but complicated, so we accept the failure (for now)
         We know from manual tests that asarray() is correct for all backends.
        TestUniformSpread::test_backend_asarray
        TestUniformSpread::test_prec_asarray
        TestUniformSpread::test_value_asarray
        TestNUFFT1::test_backend_asarray [NUFFT1 errors are due to UniformSpread]
        TestNUFFT1::test_prec_asarray
        TestNUFFT1::test_value_asarray
    [OK] DASK-case: Fixture[_op_asarray, width=DOUBLE] does not denote the true ground-truth due to DASK-based FFT()
         error accumulation.  Not really a problem because errors are in 1e-7 range, but did not look into how to fix
         them yet.
        TestFFT::test_value_asarray
        TestCZT::test_value_asarray
        TestFFS::test_value_asarray
    [OK] DASK-case: fails because generated test data does not match chunking structure of (`op._x`, `op._v`).
         These tests were not designed with chunk-size restrictions in mind. Can probably make then chunk-aware,
         but not a priority at the moment.
         We note that these tests work on NUMPY inputs, so the operators are correct.
        TestNUFFT1::test_math_adjoint
        TestNUFFT1::test_math_gram
        TestNUFFT1::test_math_lipschitz
        TestNUFFT1::test_math2_lipschitz
        TestNUFFT1::test_math3_lipschitz
        TestNUFFT1::test_value1D_svdvals
        TestNUFFT3::test_math_adjoint
        TestNUFFT3::test_math_gram
        TestNUFFT3::test_math_lipschitz
        TestNUFFT3::test_math2_lipschitz
        TestNUFFT3::test_math3_lipschitz
        TestNUFFT3::test_value1D_svdvals
